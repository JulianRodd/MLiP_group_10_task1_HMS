{"cells":[{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Import Libraries</b><a class='anchor' id='import_libraries'></a> [↑](#top)\n","\n","---\n","\n","Import all the required libraries for this notebook.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-14T15:20:21.137241Z","iopub.status.busy":"2024-03-14T15:20:21.136884Z","iopub.status.idle":"2024-03-14T15:20:27.896989Z","shell.execute_reply":"2024-03-14T15:20:27.896006Z","shell.execute_reply.started":"2024-03-14T15:20:21.137210Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]},{"name":"stdout","output_type":"stream","text":["Using 1 GPU(s)\n"]}],"source":["import albumentations as A\n","import gc\n","import matplotlib.pyplot as plt\n","import math\n","import multiprocessing\n","import numpy as np\n","import os\n","import pandas as pd\n","import random\n","import time\n","import timm\n","import torch\n","import torch.nn as nn\n","\n","\n","from albumentations.pytorch import ToTensorV2\n","from glob import glob\n","from torch.utils.data import DataLoader, Dataset\n","from tqdm import tqdm\n","from typing import Dict, List\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using\", torch.cuda.device_count(), \"GPU(s)\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-14T15:20:27.899478Z","iopub.status.busy":"2024-03-14T15:20:27.898790Z","iopub.status.idle":"2024-03-14T15:20:28.097162Z","shell.execute_reply":"2024-03-14T15:20:28.096424Z","shell.execute_reply.started":"2024-03-14T15:20:27.899441Z"},"trusted":true},"outputs":[],"source":["from kaggle_secrets import (\n","    UserSecretsClient,\n",")  # see https://www.kaggle.com/discussions/product-feedback/114053 for more info\n","import sys\n","\n","\n","user_secrets = UserSecretsClient()\n","personal_token = user_secrets.get_secret(\"git-pat\")"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-14T15:20:28.098452Z","iopub.status.busy":"2024-03-14T15:20:28.098178Z","iopub.status.idle":"2024-03-14T15:20:30.258483Z","shell.execute_reply":"2024-03-14T15:20:30.257559Z","shell.execute_reply.started":"2024-03-14T15:20:28.098429Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'MLiP_group_10_task1_HMS'...\n","remote: Enumerating objects: 780, done.\u001b[K\n","remote: Counting objects: 100% (195/195), done.\u001b[K\n","remote: Compressing objects: 100% (144/144), done.\u001b[K\n","remote: Total 780 (delta 94), reused 130 (delta 50), pack-reused 585\u001b[K\n","Receiving objects: 100% (780/780), 8.21 MiB | 26.19 MiB/s, done.\n","Resolving deltas: 100% (477/477), done.\n"]}],"source":["# !git clone https://{personal_token}@github.com/JulianRodd/MLiP_group_10_task1_HMS.git # for generic \n","branch = \"preprocessing\"\n","!git clone -b {branch} https://{personal_token}@github.com/JulianRodd/MLiP_group_10_task1_HMS.git # for branch\n","    \n","os.chdir(\"/kaggle/working/MLiP_group_10_task1_HMS\")\n","sys.path.insert(1, \"/kaggle/working/MLiP_group_10_task1_HMS\") # pos 1 to avoid conflicts"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-14T15:20:30.261068Z","iopub.status.busy":"2024-03-14T15:20:30.260766Z","iopub.status.idle":"2024-03-14T15:20:30.270429Z","shell.execute_reply":"2024-03-14T15:20:30.269515Z","shell.execute_reply.started":"2024-03-14T15:20:30.261040Z"},"trusted":true},"outputs":[],"source":["from utils.data_preprocessing_utils import filter_by_agreement, filter_by_annotators"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-14T15:20:30.271884Z","iopub.status.busy":"2024-03-14T15:20:30.271561Z","iopub.status.idle":"2024-03-14T15:20:41.232341Z","shell.execute_reply":"2024-03-14T15:20:41.231567Z","shell.execute_reply.started":"2024-03-14T15:20:30.271852Z"},"trusted":true},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","from sklearn.metrics import mean_squared_error\n","\n","\n","if not os.path.exists(\"tensorboard\"):\n","    os.mkdir(\"tensorboard\")\n","WRITER = SummaryWriter(log_dir=os.path.join(\"tensorboard\", f\"shufflenet small\"))"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Configuration</b><a class='anchor' id='configuration'></a> [↑](#top)\n","\n","---\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-14T15:20:41.233944Z","iopub.status.busy":"2024-03-14T15:20:41.233412Z","iopub.status.idle":"2024-03-14T15:20:41.241135Z","shell.execute_reply":"2024-03-14T15:20:41.240246Z","shell.execute_reply.started":"2024-03-14T15:20:41.233918Z"},"papermill":{"duration":0.016556,"end_time":"2024-01-14T22:51:51.671783","exception":false,"start_time":"2024-01-14T22:51:51.655227","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class config:\n","    AMP = True\n","    BATCH_SIZE_TRAIN = 32\n","    BATCH_SIZE_VALID = 32\n","    EPOCHS = 10\n","    FOLDS = 5\n","    FREEZE = False\n","    GRADIENT_ACCUMULATION_STEPS = 1\n","    MAX_GRAD_NORM = 1e7\n","    MODEL = \"tf_efficientnet_b0\"  # \"shufflenet_v2_x1_0\"\n","    NUM_FROZEN_LAYERS = 39\n","    NUM_WORKERS = 0  # multiprocessing.cpu_count()\n","    PRINT_FREQ = 20\n","    SEED = 20\n","    TRAIN_FULL_DATA = False\n","    VISUALIZE = True\n","    WEIGHT_DECAY = 0.01\n","    LARGE_CLASSIFIER = False\n","\n","    n_annot_late = False\n","    n_annot_early = True  # this is before splitting train and val! --> will do full set\n","    train_n_annot_min = 7\n","    train_n_annot_max = np.inf\n","    val_n_annot_min = 0\n","    val_n_annot_max = np.inf\n","\n","\n","class paths:\n","    OUTPUT_DIR = \"/kaggle/working/\"\n","    PRE_LOADED_EEGS = (\n","        \"/kaggle/input/final-preprocessed-data/eeg_specs_normalized_final.npy\"\n","    )\n","    PRE_LOADED_SPECTOGRAMS = (\n","        \"/kaggle/input/final-preprocessed-data/kaggle_specs_normalized_final.npy\"\n","    )\n","    TRAIN_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\"\n","    TRAIN_EEGS = \"/kaggle/input/brain-eeg-spectrograms/EEG_Spectrograms/\"\n","    TRAIN_SPECTOGRAMS = (\n","        \"/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/\"\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Utils</b><a class='anchor' id='utils'></a> [↑](#top)\n","\n","---\n","\n","Utility functions.\n"]},{"cell_type":"code","execution_count":7,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-03-14T15:20:41.242738Z","iopub.status.busy":"2024-03-14T15:20:41.242469Z","iopub.status.idle":"2024-03-14T15:20:41.278351Z","shell.execute_reply":"2024-03-14T15:20:41.277568Z","shell.execute_reply.started":"2024-03-14T15:20:41.242715Z"},"trusted":true},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s: float):\n","    \"Convert to minutes.\"\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since: float, percent: float):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def get_logger(filename=paths.OUTPUT_DIR):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","\n","def plot_spectrogram(spectrogram_path: str):\n","    \"\"\"\n","    Source: https://www.kaggle.com/code/mvvppp/hms-eda-and-domain-journey\n","    Visualize spectogram recordings from a parquet file.\n","    :param spectrogram_path: path to the spectogram parquet.\n","    \"\"\"\n","    sample_spect = pd.read_parquet(spectrogram_path)\n","\n","    split_spect = {\n","        \"LL\": sample_spect.filter(regex=\"^LL\", axis=1),\n","        \"RL\": sample_spect.filter(regex=\"^RL\", axis=1),\n","        \"RP\": sample_spect.filter(regex=\"^RP\", axis=1),\n","        \"LP\": sample_spect.filter(regex=\"^LP\", axis=1),\n","    }\n","\n","    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 12))\n","    axes = axes.flatten()\n","    label_interval = 5\n","    for i, split_name in enumerate(split_spect.keys()):\n","        ax = axes[i]\n","        img = ax.imshow(\n","            np.log(split_spect[split_name]).T,\n","            cmap=\"viridis\",\n","            aspect=\"auto\",\n","            origin=\"lower\",\n","        )\n","        cbar = fig.colorbar(img, ax=ax)\n","        cbar.set_label(\"Log(Value)\")\n","        ax.set_title(split_name)\n","        ax.set_ylabel(\"Frequency (Hz)\")\n","        ax.set_xlabel(\"Time\")\n","\n","        ax.set_yticks(np.arange(len(split_spect[split_name].columns)))\n","        ax.set_yticklabels(\n","            [column_name[3:] for column_name in split_spect[split_name].columns]\n","        )\n","        frequencies = [\n","            column_name[3:] for column_name in split_spect[split_name].columns\n","        ]\n","        ax.set_yticks(\n","            np.arange(0, len(split_spect[split_name].columns), label_interval)\n","        )\n","        ax.set_yticklabels(frequencies[::label_interval])\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","\n","\n","def sep():\n","    print(\"-\" * 100)\n","\n","\n","target_preds = [\n","    x + \"_pred\"\n","    for x in [\n","        \"seizure_vote\",\n","        \"lpd_vote\",\n","        \"gpd_vote\",\n","        \"lrda_vote\",\n","        \"grda_vote\",\n","        \"other_vote\",\n","    ]\n","]\n","label_to_num = {\"Seizure\": 0, \"LPD\": 1, \"GPD\": 2, \"LRDA\": 3, \"GRDA\": 4, \"Other\": 5}\n","num_to_label = {v: k for k, v in label_to_num.items()}\n","LOGGER = get_logger()\n","seed_everything(config.SEED)"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Load Data</b><a class='anchor' id='load_data'></a> [↑](#top)\n","\n","---\n","\n","Load the competition's data.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-14T15:20:41.279758Z","iopub.status.busy":"2024-03-14T15:20:41.279514Z","iopub.status.idle":"2024-03-14T15:20:41.590510Z","shell.execute_reply":"2024-03-14T15:20:41.589618Z","shell.execute_reply.started":"2024-03-14T15:20:41.279738Z"},"papermill":{"duration":0.288611,"end_time":"2024-01-14T22:51:51.984993","exception":false,"start_time":"2024-01-14T22:51:51.696382","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train cataframe shape is: (106800, 15)\n","Labels: ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n","Train cataframe shape is: (39949, 15)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eeg_id</th>\n","      <th>eeg_sub_id</th>\n","      <th>eeg_label_offset_seconds</th>\n","      <th>spectrogram_id</th>\n","      <th>spectrogram_sub_id</th>\n","      <th>spectrogram_label_offset_seconds</th>\n","      <th>label_id</th>\n","      <th>patient_id</th>\n","      <th>expert_consensus</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9</th>\n","      <td>2277392603</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>924234</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1978807404</td>\n","      <td>30539</td>\n","      <td>GPD</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>2277392603</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>924234</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>134339127</td>\n","      <td>30539</td>\n","      <td>GPD</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>722738444</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>999431</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>557980729</td>\n","      <td>56885</td>\n","      <td>LRDA</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>722738444</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>999431</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>1949834128</td>\n","      <td>56885</td>\n","      <td>LRDA</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>722738444</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>999431</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3790867376</td>\n","      <td>56885</td>\n","      <td>LRDA</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        eeg_id  eeg_sub_id  eeg_label_offset_seconds  spectrogram_id  \\\n","9   2277392603           0                       0.0          924234   \n","10  2277392603           1                       2.0          924234   \n","11   722738444           0                       0.0          999431   \n","12   722738444           1                       2.0          999431   \n","13   722738444           2                       4.0          999431   \n","\n","    spectrogram_sub_id  spectrogram_label_offset_seconds    label_id  \\\n","9                    0                               0.0  1978807404   \n","10                   1                               2.0   134339127   \n","11                   0                               0.0   557980729   \n","12                   1                               2.0  1949834128   \n","13                   2                               4.0  3790867376   \n","\n","    patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  lrda_vote  \\\n","9        30539              GPD             0         0         5          0   \n","10       30539              GPD             0         0         5          0   \n","11       56885             LRDA             0         1         0         14   \n","12       56885             LRDA             0         1         0         14   \n","13       56885             LRDA             0         1         0         14   \n","\n","    grda_vote  other_vote  \n","9           1           5  \n","10          1           5  \n","11          0           1  \n","12          0           1  \n","13          0           1  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(paths.TRAIN_CSV)\n","label_cols = df.columns[-6:]\n","print(f\"Train cataframe shape is: {df.shape}\")\n","print(f\"Labels: {list(label_cols)}\")\n","\n","if config.n_annot_early:\n","    df = filter_by_annotators(df, config.train_n_annot_min, config.train_n_annot_max)\n","\n","filter_by_agree = False\n","if filter_by_agree:\n","    df = filter_by_agreement(df, 0)\n","print(f\"Train cataframe shape is: {df.shape}\")\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Non Overalpping EEG specs\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-14T15:20:41.592344Z","iopub.status.busy":"2024-03-14T15:20:41.591742Z","iopub.status.idle":"2024-03-14T15:20:41.923101Z","shell.execute_reply":"2024-03-14T15:20:41.921986Z","shell.execute_reply.started":"2024-03-14T15:20:41.592310Z"},"papermill":{"duration":0.111621,"end_time":"2024-01-14T22:51:52.125134","exception":false,"start_time":"2024-01-14T22:51:52.013513","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train non-overlapp eeg_id shape: (5939, 13)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eeg_id</th>\n","      <th>spectogram_id</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>patient_id</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","      <th>n_annot</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>568657</td>\n","      <td>789577333</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>20654</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.250000</td>\n","      <td>0.000000</td>\n","      <td>0.166667</td>\n","      <td>0.583333</td>\n","      <td>48</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>582999</td>\n","      <td>1552638400</td>\n","      <td>0.0</td>\n","      <td>38.0</td>\n","      <td>20230</td>\n","      <td>0.000000</td>\n","      <td>0.857143</td>\n","      <td>0.000000</td>\n","      <td>0.071429</td>\n","      <td>0.000000</td>\n","      <td>0.071429</td>\n","      <td>154</td>\n","      <td>LPD</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1895581</td>\n","      <td>128369999</td>\n","      <td>1138.0</td>\n","      <td>1138.0</td>\n","      <td>47999</td>\n","      <td>0.076923</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.076923</td>\n","      <td>0.846154</td>\n","      <td>13</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2482631</td>\n","      <td>978166025</td>\n","      <td>1902.0</td>\n","      <td>1944.0</td>\n","      <td>20606</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.133333</td>\n","      <td>0.066667</td>\n","      <td>0.133333</td>\n","      <td>0.666667</td>\n","      <td>105</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2521897</td>\n","      <td>673742515</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>62117</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.083333</td>\n","      <td>0.083333</td>\n","      <td>0.333333</td>\n","      <td>0.500000</td>\n","      <td>24</td>\n","      <td>Other</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    eeg_id  spectogram_id     min     max  patient_id  seizure_vote  lpd_vote  \\\n","0   568657      789577333     0.0    16.0       20654      0.000000  0.000000   \n","1   582999     1552638400     0.0    38.0       20230      0.000000  0.857143   \n","2  1895581      128369999  1138.0  1138.0       47999      0.076923  0.000000   \n","3  2482631      978166025  1902.0  1944.0       20606      0.000000  0.000000   \n","4  2521897      673742515     0.0     4.0       62117      0.000000  0.000000   \n","\n","   gpd_vote  lrda_vote  grda_vote  other_vote  n_annot target  \n","0  0.250000   0.000000   0.166667    0.583333       48  Other  \n","1  0.000000   0.071429   0.000000    0.071429      154    LPD  \n","2  0.000000   0.000000   0.076923    0.846154       13  Other  \n","3  0.133333   0.066667   0.133333    0.666667      105  Other  \n","4  0.083333   0.083333   0.333333    0.500000       24  Other  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_df = df.groupby(\"eeg_id\")[\n","    [\"spectrogram_id\", \"spectrogram_label_offset_seconds\"]\n","].agg({\"spectrogram_id\": \"first\", \"spectrogram_label_offset_seconds\": \"min\"})\n","train_df.columns = [\"spectogram_id\", \"min\"]\n","\n","aux = df.groupby(\"eeg_id\")[[\"spectrogram_id\", \"spectrogram_label_offset_seconds\"]].agg(\n","    {\"spectrogram_label_offset_seconds\": \"max\"}\n",")\n","train_df[\"max\"] = aux\n","\n","aux = df.groupby(\"eeg_id\")[[\"patient_id\"]].agg(\"first\")\n","train_df[\"patient_id\"] = aux\n","\n","aux = df.groupby(\"eeg_id\")[label_cols].agg(\"sum\")\n","for label in label_cols:\n","    train_df[label] = aux[label].values\n","\n","\n","y_data = train_df[label_cols].values\n","train_df[\"n_annot\"] = y_data.sum(axis=1, keepdims=True)\n","y_data = y_data / y_data.sum(axis=1, keepdims=True)\n","train_df[label_cols] = y_data\n","\n","aux = df.groupby(\"eeg_id\")[[\"expert_consensus\"]].agg(\"first\")\n","train_df[\"target\"] = aux\n","\n","train_df = train_df.reset_index()\n","print(\"Train non-overlapp eeg_id shape:\", train_df.shape)\n","train_df.head()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.00881,"end_time":"2024-01-14T22:51:52.142747","exception":false,"start_time":"2024-01-14T22:51:52.133937","status":"completed"},"tags":[]},"source":["### <b><span style='color:#F1A424'>Read Train Spectrograms</span></b>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-14T15:20:41.926577Z","iopub.status.busy":"2024-03-14T15:20:41.926294Z"},"papermill":{"duration":55.16894,"end_time":"2024-01-14T22:52:47.320438","exception":false,"start_time":"2024-01-14T22:51:52.151498","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 11138 spectrogram parquets\n"]}],"source":["%%time\n","READ_SPEC_FILES = False\n","\n","paths_spectograms = glob(paths.TRAIN_SPECTOGRAMS + \"*.parquet\")\n","print(f'There are {len(paths_spectograms)} spectrogram parquets')\n","\n","if READ_SPEC_FILES:    \n","    all_spectrograms = {}\n","    for file_path in tqdm(paths_spectograms):\n","        aux = pd.read_parquet(file_path)\n","        name = int(file_path.split(\"/\")[-1].split('.')[0])\n","        all_spectrograms[name] = aux.iloc[:,1:].values\n","        del aux\n","else:\n","    all_spectrograms = np.load(paths.PRE_LOADED_SPECTOGRAMS, allow_pickle=True).item()\n","    \n","if config.VISUALIZE:\n","    idx = np.random.randint(0,len(paths_spectograms))\n","    spectrogram_path = paths_spectograms[idx]\n","    plot_spectrogram(spectrogram_path)"]},{"cell_type":"markdown","metadata":{},"source":["### <b><span style='color:#F1A424'>Read EEG Spectrograms</span></b>\n","\n","The resulting `all_eegs` dictionary contains `eeg_id` as keys (`int` keys) and the values are the eeg sequences (as 3-dimensional `np.array`) of shape `(128, 256, 4)`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","READ_EEG_SPEC_FILES = False\n","\n","paths_eegs = glob(paths.TRAIN_EEGS + \"*.npy\")\n","print(f'There are {len(paths_eegs)} EEG spectograms')\n","\n","if READ_EEG_SPEC_FILES:\n","    all_eegs = {}\n","    for file_path in tqdm(paths_eegs):\n","        eeg_id = file_path.split(\"/\")[-1].split(\".\")[0]\n","        eeg_spectogram = np.load(file_path)\n","        all_eegs[eeg_id] = eeg_spectogram\n","else:\n","    all_eegs = np.load(paths.PRE_LOADED_EEGS, allow_pickle=True).item()"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Validation</b><a class='anchor' id='validation'></a> [↑](#top)\n","\n","---\n","\n","We train using `GroupKFold` on `patient_id`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.model_selection import KFold, GroupKFold\n","\n","\n","gkf = GroupKFold(n_splits=config.FOLDS)\n","for fold, (train_index, valid_index) in enumerate(\n","    gkf.split(train_df, train_df.target, train_df.patient_id)\n","):\n","    train_df.loc[valid_index, \"fold\"] = int(fold)\n","\n","display(train_df.groupby(\"fold\").size()), sep()\n","display(train_df.head())"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Dataset</b><a class='anchor' id='dataset'></a> [↑](#top)\n","\n","---\n","\n","Create a custom `Dataset` to load data.\n","\n","Our dataloader outputs both Kaggle spectrograms and EEG spectrogams as 8 channel image of size `(128, 256, 8)`\n","\n","[1]: https://www.kaggle.com/code/cdeotte/efficientnetb0-starter-lb-0-43/comments#2617811\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(\n","        self,\n","        df: pd.DataFrame,\n","        config,\n","        augment: bool = False,\n","        mode: str = \"train\",\n","        specs: Dict[int, np.ndarray] = all_spectrograms,\n","        eeg_specs: Dict[int, np.ndarray] = all_eegs,\n","    ):\n","        self.df = df\n","        self.config = config\n","        self.batch_size = self.config.BATCH_SIZE_TRAIN\n","        self.augment = augment\n","        self.mode = mode\n","        self.spectograms = all_spectrograms\n","        self.eeg_spectograms = eeg_specs\n","\n","    def __len__(self):\n","        \"\"\"\n","        Denotes the number of batches per epoch.\n","        \"\"\"\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Generate one batch of data.\n","        \"\"\"\n","        X, y = self.__data_generation(index)\n","        if self.augment:\n","            X = self.__transform(X)\n","        return torch.tensor(X, dtype=torch.float32), torch.tensor(\n","            y, dtype=torch.float32\n","        )\n","\n","    def __data_generation(self, index):\n","        \"\"\"\n","        Generates data containing batch_size samples.\n","        \"\"\"\n","        X = np.zeros((128, 256, 8), dtype=\"float32\")\n","        y = np.zeros(6, dtype=\"float32\")\n","        img = np.ones((128, 256), dtype=\"float32\")\n","        row = self.df.iloc[index]\n","        if self.mode == \"test\":\n","            r = 0\n","        else:\n","            r = int((row[\"min\"] + row[\"max\"]) // 4)\n","\n","        for region in range(4):\n","            img = self.spectograms[row.spectogram_id][\n","                r : r + 300, region * 100 : (region + 1) * 100\n","            ].T\n","\n","            # Log transform spectogram\n","            img = np.clip(img, np.exp(-4), np.exp(8))\n","            img = np.log(img)\n","\n","            # Standarize per image\n","            ep = 1e-6\n","            mu = np.nanmean(img.flatten())\n","            std = np.nanstd(img.flatten())\n","            img = (img - mu) / (std + ep)\n","            img = np.nan_to_num(img, nan=0.0)\n","            X[14:-14, :, region] = img[:, 22:-22] / 2.0\n","            img = self.eeg_spectograms[row.eeg_id]\n","            X[:, :, 4:] = img\n","\n","            if self.mode != \"test\":\n","                y = row[label_cols].values.astype(np.float32)\n","\n","        return X, y\n","\n","    def __transform(self, img):\n","        transforms = A.Compose(\n","            [\n","                A.HorizontalFlip(p=0.5),\n","            ]\n","        )\n","        return transforms(image=img)[\"image\"]"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> DataLoader</b><a class='anchor' id='dataloader'></a> [↑](#top)\n","\n","---\n","\n","Below we display example dataloader spectrogram images.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_dataset = CustomDataset(train_df, config, mode=\"train\")\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=config.BATCH_SIZE_TRAIN,\n","    shuffle=False,\n","    num_workers=config.NUM_WORKERS,\n","    pin_memory=True,\n","    drop_last=True,\n",")\n","X, y = train_dataset[0]\n","print(f\"X shape: {X.shape}\")\n","print(f\"y shape: {y.shape}\")"]},{"cell_type":"markdown","metadata":{},"source":["### <b><span style='color:#F1A424'> Visualize DataLoader</span></b>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["if config.VISUALIZE:\n","    ROWS = 2\n","    COLS = 3\n","    for X, y in train_loader:\n","        plt.figure(figsize=(20, 8))\n","        for row in range(ROWS):\n","            for col in range(COLS):\n","                plt.subplot(ROWS, COLS, row * COLS + col + 1)\n","                t = y[row * COLS + col]\n","                img = X[row * COLS + col, :, :, 0]\n","                mn = img.flatten().min()\n","                mx = img.flatten().max()\n","                img = (img - mn) / (mx - mn)\n","                plt.imshow(img)\n","                tars = f\"[{t[0]:0.2f}\"\n","                for s in t[1:]:\n","                    tars += f\", {s:0.2f}\"\n","                eeg = train_df.eeg_id.values[\n","                    row * config.BATCH_SIZE_TRAIN + row * COLS + col\n","                ]\n","                plt.title(f\"EEG = {eeg}\\nTarget = {tars}\", size=12)\n","                plt.yticks([])\n","                plt.ylabel(\"Frequencies (Hz)\", size=14)\n","                plt.xlabel(\"Time (sec)\", size=16)\n","        plt.show()\n","        break"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Model</b><a class='anchor' id='model'></a> [↑](#top)\n","\n","---\n","\n","We will be using the [timm](https://github.com/huggingface/pytorch-image-models) library for our models.\n","\n","Our models receives both Kaggle spectrograms and EEG spectrograms from our data loader. We then reshape these 8 spectrograms into 1 large flat image and feed it into EfficientNet.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, config, num_classes: int = 6, pretrained: bool = True):\n","        super(CustomModel, self).__init__()\n","        self.config = config\n","        self.num_classes = num_classes\n","        self.USE_KAGGLE_SPECTROGRAMS = True\n","        self.USE_EEG_SPECTROGRAMS = True\n","        self.model = (\n","            timm.create_model(\n","                config.MODEL,\n","                pretrained=True,\n","                drop_rate=0.1,\n","                drop_path_rate=0.2,\n","            )\n","            if config.MODEL.startswith(\"tf_\")\n","            else torch.hub.load(\"pytorch/vision:v0.10.0\", config.MODEL, pretrained=True)\n","        )\n","\n","        if config.FREEZE:\n","            for i, (name, param) in enumerate(\n","                list(self.model.named_parameters())[0 : config.NUM_FROZEN_LAYERS]\n","            ):\n","                param.requires_grad = False\n","\n","        self.features = self.set_feature_layers()\n","        self.custom_layers = self.set_custom_layers()\n","\n","    def set_custom_layers(self):\n","        # this should probs become a dict once we know which sizes we are going to use\n","        if self.config.MODEL.startswith(\"tf_\"):\n","            num_features = self.model.num_features\n","        elif self.config.MODEL.startswith(\"shufflenet\"):\n","            num_features = 1024  # need to make this better\n","        elif self.config.MODEL.startswith(\"resnet\"):\n","            num_features = 2048\n","        else:\n","            raise NotImplementedError(\"Model not implemented - check model name.\")\n","\n","        if getattr(\n","            self.config, \"LARGE_CLASSIFIER\", False\n","        ):  # not all will have attribute so to not break it return False if attr does not exist\n","            return nn.Sequential(\n","                nn.AdaptiveAvgPool2d(1),\n","                nn.Flatten(),\n","                nn.Linear(num_features, 256),\n","                nn.BatchNorm1d(\n","                    256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","                ),\n","                nn.ReLU(inplace=True),\n","                nn.Linear(256, self.num_classes),\n","            )\n","\n","        else:\n","            return nn.Sequential(\n","                nn.AdaptiveAvgPool2d(1),\n","                nn.Flatten(),\n","                nn.Linear(num_features, self.num_classes),\n","            )\n","\n","    def set_feature_layers(self):\n","        if self.config.MODEL.startswith(\"tf_\") or self.config.MODEL.startswith(\n","            \"resnet\"\n","        ):\n","            return nn.Sequential(*list(self.model.children())[:-2])\n","\n","        elif self.config.MODEL.startswith(\"shufflenet\"):\n","            return nn.Sequential(*list(self.model.children())[:-1])\n","\n","    def __reshape_input(self, x):\n","        \"\"\"\n","        Reshapes input (128, 256, 8) -> (512, 512, 3) monotone image.\n","        \"\"\"\n","        # === Get spectograms ===\n","        spectograms = [x[:, :, :, i : i + 1] for i in range(4)]\n","        spectograms = torch.cat(spectograms, dim=1)\n","\n","        # === Get EEG spectograms ===\n","        eegs = [x[:, :, :, i : i + 1] for i in range(4, 8)]\n","        eegs = torch.cat(eegs, dim=1)\n","\n","        # === Reshape (512,512,3) ===\n","        if self.USE_KAGGLE_SPECTROGRAMS & self.USE_EEG_SPECTROGRAMS:\n","            x = torch.cat([spectograms, eegs], dim=2)\n","        elif self.USE_EEG_SPECTROGRAMS:\n","            x = eegs\n","        else:\n","            x = spectograms\n","\n","        x = torch.cat([x, x, x], dim=3)\n","        x = x.permute(0, 3, 1, 2)\n","        return x\n","\n","    def forward(self, x):\n","        x = self.__reshape_input(x)\n","        x = self.features(x)\n","        x = self.custom_layers(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Scheduler</b><a class='anchor' id='scheduler'></a> [↑](#top)\n","\n","---\n","\n","We will train our model with a Step Train Schedule for 4 epochs. First 2 epochs are LR=1e-3. Then epochs 3 and 4 use LR=1e-4 and 1e-5 respectively. (Below we also provide a Cosine Train Schedule if you want to experiment with it. Note it is not used in this notebook).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["from torch.optim.lr_scheduler import OneCycleLR\n","\n","EPOCHS = config.EPOCHS\n","BATCHES = len(train_loader)\n","steps = []\n","lrs = []\n","optim_lrs = []\n","model = CustomModel(config)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n","scheduler = OneCycleLR(\n","    optimizer,\n","    max_lr=1e-3,\n","    epochs=config.EPOCHS,\n","    steps_per_epoch=len(train_loader),\n","    pct_start=0.05,\n","    anneal_strategy=\"cos\",\n","    final_div_factor=100,\n",")\n","for epoch in range(EPOCHS):\n","    for batch in range(BATCHES):\n","        scheduler.step()\n","        lrs.append(scheduler.get_last_lr()[0])\n","        steps.append(epoch * BATCHES + batch)\n","\n","max_lr = max(lrs)\n","min_lr = min(lrs)\n","print(f\"Maximum LR: {max_lr} | Minimum LR: {min_lr}\")\n","plt.figure()\n","plt.plot(steps, lrs, label=\"OneCycle\")\n","plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n","plt.xlabel(\"Step\")\n","plt.ylabel(\"Learning Rate\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Loss Function</b><a class='anchor' id='loss'></a> [↑](#top)\n","\n","---\n","\n","In PyTorch's [KLDivLoss][1], the reduction parameter determines how the loss is aggregated across different dimensions. Two common options are `mean` and `batchmean`.\n","\n","- `reduction`='mean': When reduction is set to \"mean\", the Kullback-Leibler Divergence loss is computed and then averaged over all the elements in the input tensor. The result is a scalar value representing the mean loss.\n","- `reduction`='batchmean': When reduction is set to \"batchmean\", the Kullback-Leibler Divergence loss is computed independently for each item in the batch, and then the mean is taken over the batch dimension. This is useful when you have a batch of samples, and you want the average loss per sample.\n","\n","[1]: https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","\n","# === Reduction = \"mean\" ===\n","criterion = nn.KLDivLoss(reduction=\"mean\")\n","y_pred = F.log_softmax(torch.randn(6, 2, requires_grad=True), dim=1)\n","y_true = F.softmax(torch.rand(6, 2), dim=1)\n","print(f\"Predictions: {y_pred}\")\n","print(f\"Targets: {y_true}\")\n","output = criterion(y_pred, y_true)\n","print(f\"Output: {output}\")\n","\n","print(\"\\n\", \"=\" * 100, \"\\n\")\n","\n","# === Reduction = \"batchmean\" ===\n","criterion = nn.KLDivLoss(reduction=\"batchmean\")\n","y_pred = F.log_softmax(torch.randn(2, 6, requires_grad=True), dim=1)\n","y_true = F.softmax(torch.rand(2, 6), dim=1)\n","print(f\"Predictions: {y_pred}\")\n","print(f\"Targets: {y_true}\")\n","output = criterion(y_pred, y_true)\n","print(f\"Output: {output}\")"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.033717,"end_time":"2024-01-14T22:53:06.742557","exception":false,"start_time":"2024-01-14T22:53:06.70884","status":"completed"},"tags":[]},"source":["# <b><span style='color:#F1A424'>|</span> Train and Validation Functions</b><a class='anchor' id='functions'></a> [↑](#top)\n","\n","---\n","\n","We train using Group KFold on patient id. If `LOAD_MODELS_FROM = None`, then we will train new models in this notebook version. Otherwise we will load saved models from the path `LOAD_MODELS_FROM`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    \"\"\"One epoch training pass.\"\"\"\n","    model.train()\n","    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n","    scaler = torch.cuda.amp.GradScaler(enabled=config.AMP)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","\n","    # ========== ITERATE OVER TRAIN BATCHES ============\n","    with tqdm(train_loader, unit=\"train_batch\", desc=\"Train\") as tqdm_train_loader:\n","        for step, (X, y) in enumerate(tqdm_train_loader):\n","            X = X.to(device)\n","            y = y.to(device)\n","            batch_size = y.size(0)\n","            with torch.cuda.amp.autocast(enabled=config.AMP):\n","                y_preds = model(X)\n","                loss = criterion(F.log_softmax(y_preds, dim=1), y)\n","            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n","                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n","            losses.update(loss.item(), batch_size)\n","            scaler.scale(loss).backward()\n","            grad_norm = torch.nn.utils.clip_grad_norm_(\n","                model.parameters(), config.MAX_GRAD_NORM\n","            )\n","\n","            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n","                scaler.step(optimizer)\n","                scaler.update()\n","                optimizer.zero_grad()\n","                global_step += 1\n","                scheduler.step()\n","            end = time.time()\n","\n","            # ========== LOG INFO ==========\n","            if step % config.PRINT_FREQ == 0 or step == (len(train_loader) - 1):\n","                print(\n","                    \"Epoch: [{0}][{1}/{2}] \"\n","                    \"Elapsed {remain:s} \"\n","                    \"Loss: {loss.avg:.4f} \"\n","                    \"Grad: {grad_norm:.4f}  \"\n","                    \"LR: {lr:.8f}  \".format(\n","                        epoch + 1,\n","                        step,\n","                        len(train_loader),\n","                        remain=timeSince(start, float(step + 1) / len(train_loader)),\n","                        loss=losses,\n","                        grad_norm=grad_norm,\n","                        lr=scheduler.get_last_lr()[0],\n","                    )\n","                )\n","\n","    return losses.avg\n","\n","\n","def valid_epoch(valid_loader, model, criterion, device):\n","    model.eval()\n","    softmax = nn.Softmax(dim=1)\n","    losses = AverageMeter()\n","    prediction_dict = {}\n","    preds = []\n","    start = end = time.time()\n","    with tqdm(valid_loader, unit=\"valid_batch\", desc=\"Validation\") as tqdm_valid_loader:\n","        for step, (X, y) in enumerate(tqdm_valid_loader):\n","            X = X.to(device)\n","            y = y.to(device)\n","            batch_size = y.size(0)\n","            with torch.no_grad():\n","                y_preds = model(X)\n","                loss = criterion(F.log_softmax(y_preds, dim=1), y)\n","            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n","                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n","            losses.update(loss.item(), batch_size)\n","            y_preds = softmax(y_preds)\n","            preds.append(y_preds.to(\"cpu\").numpy())\n","            end = time.time()\n","\n","            # ========== LOG INFO ==========\n","            if step % config.PRINT_FREQ == 0 or step == (len(valid_loader) - 1):\n","                print(\n","                    \"EVAL: [{0}/{1}] \"\n","                    \"Elapsed {remain:s} \"\n","                    \"Loss: {loss.avg:.4f} \".format(\n","                        step,\n","                        len(valid_loader),\n","                        remain=timeSince(start, float(step + 1) / len(valid_loader)),\n","                        loss=losses,\n","                    )\n","                )\n","\n","    prediction_dict[\"predictions\"] = np.concatenate(preds)\n","    return losses.avg, prediction_dict"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Train Loop</b><a class='anchor' id='train_loop'></a> [↑](#top)\n","\n","---\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_loop(df, fold):\n","\n","    LOGGER.info(f\"========== Fold: {fold} training ==========\")\n","\n","    # ======== SPLIT ==========\n","    train_folds = df[df[\"fold\"] != fold].reset_index(drop=True)\n","    valid_folds = df[df[\"fold\"] == fold].reset_index(drop=True)\n","    if config.n_annot_late:\n","        train_folds = train_folds[\n","            (train_folds[\"n_annot\"] >= config.train_n_annot_min)\n","            & (train_folds[\"n_annot\"] < config.train_n_annot_max)\n","        ]\n","        valid_folds = valid_folds[\n","            (valid_folds[\"n_annot\"] >= config.val_n_annot_min)\n","            & (valid_folds[\"n_annot\"] < config.val_n_annot_max)\n","        ]\n","\n","    LOGGER.info(f\"Training on {len(train_folds)} samples.\")\n","    LOGGER.info(f\"Validating on {len(valid_folds)} samples.\")\n","\n","    # ======== DATASETS ==========\n","    train_dataset = CustomDataset(train_folds, config, mode=\"train\", augment=True)\n","    valid_dataset = CustomDataset(valid_folds, config, mode=\"train\", augment=False)\n","\n","    # ======== DATALOADERS ==========\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=config.BATCH_SIZE_TRAIN,\n","        shuffle=True,\n","        num_workers=config.NUM_WORKERS,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    valid_loader = DataLoader(\n","        valid_dataset,\n","        batch_size=config.BATCH_SIZE_VALID,\n","        shuffle=False,\n","        num_workers=config.NUM_WORKERS,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # ======== MODEL ==========\n","    model = CustomModel(config)\n","    print(f\"Model: {model.config.MODEL}, Large CF: {model.config.LARGE_CLASSIFIER}\")\n","    model.to(device)\n","\n","    optimizer = torch.optim.AdamW(\n","        model.parameters(), lr=0.1, weight_decay=config.WEIGHT_DECAY\n","    )\n","    scheduler = OneCycleLR(\n","        optimizer,\n","        max_lr=1e-3,\n","        epochs=config.EPOCHS,\n","        steps_per_epoch=len(train_loader),\n","        pct_start=0.1,\n","        anneal_strategy=\"cos\",\n","        final_div_factor=100,\n","    )\n","\n","    # ======= LOSS ==========\n","    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n","\n","    best_loss = np.inf\n","    # ====== ITERATE EPOCHS ========\n","    for epoch in range(config.EPOCHS):\n","        start_time = time.time()\n","\n","        # ======= TRAIN ==========\n","        avg_train_loss = train_epoch(\n","            train_loader, model, criterion, optimizer, epoch, scheduler, device\n","        )\n","\n","        # ======= EVALUATION ==========\n","        avg_val_loss, prediction_dict = valid_epoch(\n","            valid_loader, model, criterion, device\n","        )\n","        predictions = prediction_dict[\"predictions\"]\n","\n","        # ======= SCORING ==========\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(\n","            f\"Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n","        )\n","\n","        if avg_val_loss < best_loss:\n","            best_loss = avg_val_loss\n","            LOGGER.info(f\"Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model\")\n","            torch.save(\n","                {\"model\": model.state_dict(), \"predictions\": predictions},\n","                paths.OUTPUT_DIR\n","                + f\"/{config.MODEL.replace('/', '_')}_fold_{fold}_best_{config.LARGE_CLASSIFIER}.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        paths.OUTPUT_DIR\n","        + f\"/{config.MODEL.replace('/', '_')}_fold_{fold}_best_{config.LARGE_CLASSIFIER}.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    valid_folds[target_preds] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return valid_folds"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Train Full Data</b><a class='anchor' id='train_full'></a> [↑](#top)\n","\n","---\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_loop_full_data(df):\n","    train_dataset = CustomDataset(df, config, mode=\"train\", augment=True)\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=config.BATCH_SIZE_TRAIN,\n","        shuffle=False,\n","        num_workers=config.NUM_WORKERS,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    model = CustomModel(config)\n","    model.to(device)\n","    optimizer = torch.optim.AdamW(\n","        model.parameters(), lr=0.1, weight_decay=config.WEIGHT_DECAY\n","    )\n","    scheduler = OneCycleLR(\n","        optimizer,\n","        max_lr=1e-3,\n","        epochs=config.EPOCHS,\n","        steps_per_epoch=len(train_loader),\n","        pct_start=0.1,\n","        anneal_strategy=\"cos\",\n","        final_div_factor=100,\n","    )\n","    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n","    best_loss = np.inf\n","    for epoch in range(config.EPOCHS):\n","        start_time = time.time()\n","        avg_train_loss = train_epoch(\n","            train_loader, model, criterion, optimizer, epoch, scheduler, device\n","        )\n","        elapsed = time.time() - start_time\n","        LOGGER.info(\n","            f\"Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}  time: {elapsed:.0f}s\"\n","        )\n","        torch.save(\n","            {\"model\": model.state_dict()},\n","            paths.OUTPUT_DIR + f\"/{config.MODEL.replace('/', '_')}_epoch_{epoch}.pth\",\n","        )\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    return _"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Train</b><a class='anchor' id='train'></a> [↑](#top)\n","\n","---\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_result(oof_df):\n","    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","    labels = torch.tensor(oof_df[label_cols].values)\n","    preds = torch.tensor(oof_df[target_preds].values)\n","    preds = F.log_softmax(preds, dim=1)\n","    result = kl_loss(preds, labels)\n","    return result\n","\n","\n","if not config.TRAIN_FULL_DATA:\n","    oof_df = pd.DataFrame()\n","    for fold in range(config.FOLDS):\n","        if fold != 4:  # in [0, 1, 2, 3, 4]\n","            print(f\"Skipping fold {fold}\")\n","            continue\n","        else:\n","            _oof_df = train_loop(train_df, fold)\n","            oof_df = pd.concat([oof_df, _oof_df])\n","            LOGGER.info(\n","                f\"========== Fold {fold} result: {get_result(_oof_df)} ==========\"\n","            )\n","            print(f\"========== Fold {fold} result: {get_result(_oof_df)} ==========\")\n","    oof_df = oof_df.reset_index(drop=True)\n","    LOGGER.info(f\"========== CV: {get_result(oof_df)} ==========\")\n","    oof_df.to_csv(paths.OUTPUT_DIR + \"/oof_df.csv\", index=False)\n","else:\n","    train_loop_full_data(train_df)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"datasetId":4297749,"sourceId":7392733,"sourceType":"datasetVersion"},{"datasetId":4297782,"sourceId":7392775,"sourceType":"datasetVersion"},{"datasetId":4304475,"sourceId":7402356,"sourceType":"datasetVersion"},{"datasetId":4304949,"sourceId":7403069,"sourceType":"datasetVersion"},{"datasetId":4334995,"sourceId":7447509,"sourceType":"datasetVersion"},{"datasetId":4336944,"sourceId":7450712,"sourceType":"datasetVersion"},{"datasetId":4598348,"sourceId":7843116,"sourceType":"datasetVersion"},{"sourceId":158958765,"sourceType":"kernelVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":270.012179,"end_time":"2024-01-14T22:56:02.916427","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-14T22:51:32.904248","version":"2.4.0"}},"nbformat":4,"nbformat_minor":4}
