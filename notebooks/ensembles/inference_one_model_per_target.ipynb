{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/janneke/Documents/Master/Machine_Learning_in_Practice/HMS/MLiP_group_10_task1_HMS\n"
     ]
    }
   ],
   "source": [
    "# %cd ..\n",
    "%cd /home/janneke/Documents/Master/Machine_Learning_in_Practice/HMS/MLiP_group_10_task1_HMS/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from logging import getLogger, basicConfig, INFO\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from generics import Generics\n",
    "from datasets.raw_data_loader import CustomRawDataset\n",
    "from datasets.data_loader import CustomDataset\n",
    "from datasets.data_loader_configs import BaseDataConfig\n",
    "from utils.evaluation_utils import score_kl_divergence\n",
    "from utils.inference_utils import create_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "basicConfig(level=INFO)\n",
    "logger = getLogger('main')\n",
    "config = BaseDataConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 13:45:06,903 - data_loader.log - INFO - Loading dataset from cache: ./data/cache/CustomRawDataset_0_test.npz\n",
      "2024-02-17 13:45:06,903 - data_loader.log - INFO - Loading dataset from cache: ./data/cache/CustomRawDataset_0_test.npz\n",
      "2024-02-17 13:45:06,903 - data_loader.log - INFO - Loading dataset from cache: ./data/cache/CustomRawDataset_0_test.npz\n",
      "2024-02-17 13:45:06,903 - data_loader.log - INFO - Loading dataset from cache: ./data/cache/CustomRawDataset_0_test.npz\n",
      "INFO:data_loader.log:Loading dataset from cache: ./data/cache/CustomRawDataset_0_test.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary:\n",
      "Mode: test\n",
      "Total Samples: 1\n",
      "Unique Patients: 1\n",
      "Unique EEGs: 1\n",
      "Unique Spectrograms: 1\n",
      "Probabilities Loaded: 1\n",
      "Features Loaded: 1\n",
      "\n",
      "Configuration Summary:\n",
      "+---------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Configuration       | Value                                                                                                                                |\n",
      "+---------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| BATCH_SIZE_TEST     | 16                                                                                                                                   |\n",
      "| BATCH_SIZE_TRAIN    | 64                                                                                                                                   |\n",
      "| BATCH_SIZE_VAL      | 16                                                                                                                                   |\n",
      "| DROP_LAST           | True                                                                                                                                 |\n",
      "| EKG_FEAT            | EKG                                                                                                                                  |\n",
      "| FEATS               | [['Fp1', 'F7', 'T3', 'T5', 'O1'], ['Fp1', 'F3', 'C3', 'P3', 'O1'], ['Fp2', 'F8', 'T4', 'T6', 'O2'], ['Fp2', 'F4', 'C4', 'P4', 'O2']] |\n",
      "| NAME                | BaseDataConfig                                                                                                                       |\n",
      "| NAMES               | ['LL', 'LP', 'RP', 'RR']                                                                                                             |\n",
      "| NUM_WORKERS         | 0                                                                                                                                    |\n",
      "| ONE_CROP_PER_PERSON | True                                                                                                                                 |\n",
      "| PIN_MEMORY          | True                                                                                                                                 |\n",
      "| SHUFFLE_TRAIN       | True                                                                                                                                 |\n",
      "| SUBSET_SAMPLE_COUNT | 0                                                                                                                                    |\n",
      "| USE_WAVELET         | None                                                                                                                                 |\n",
      "| VAL_SPLIT_RATIO     | 0.2                                                                                                                                  |\n",
      "+---------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "train_subset_sample_count = 0\n",
    "test_dataset = CustomRawDataset(config, mode=\"test\", cache=True)\n",
    "test_dataset.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 187)\n"
     ]
    }
   ],
   "source": [
    "x_test = test_dataset.features_per_sample\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"checkpoints/other_models/ensemble_one_model_per_target_{train_subset_sample_count}.pickle\", \"rb\") as pickle_file:\n",
    "\tmodels = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let multiple separate models regress on one label each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(learning_rate=1.0, max_depth=1, random_state=0)\n",
      "GradientBoostingRegressor(learning_rate=1.0, max_depth=1, random_state=0)\n",
      "GradientBoostingRegressor(learning_rate=1.0, max_depth=1, random_state=0)\n",
      "GradientBoostingRegressor(learning_rate=1.0, max_depth=1, random_state=0)\n",
      "GradientBoostingRegressor(learning_rate=1.0, max_depth=1, random_state=0)\n",
      "GradientBoostingRegressor(learning_rate=1.0, max_depth=1, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.zeros((x_test.shape[0], len(models)))  # shape: num_samles, num_labels\n",
    "\n",
    "for i, (lbl, model) in enumerate(models.items()):\n",
    "\ty_pred_group = model.predict(x_test)\n",
    "\ty_pred[:,i] = y_pred_group\n",
    "\n",
    "y_pred[y_pred < 0] = 0\n",
    "y_pred_probabilities = y_pred / np.sum(y_pred, axis=1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (1, 7)\n"
     ]
    }
   ],
   "source": [
    "submission_df = create_submission(test_dataset.main_df, y_pred_probabilities, Generics.LABEL_COLS, 'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLiP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
